{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Setup & Creating Topics\n",
    "\n",
    "## Virtual Environment Setup\n",
    "\n",
    "A virtual environment is a tool that helps to keep dependencies required by different projects separate. It essentially allows you to create a virtual Python environment that is isolated from the global Python environment. This way, different projects can have different dependencies without any conflicts.\n",
    "\n",
    "### Setting up a Virtual Environment\n",
    "\n",
    "1. **Create a Virtual Environment**:\n",
    "   Navigate to your project directory in the terminal and run the following command to create a new virtual environment named `venv`:\n",
    "   \n",
    "   ```bash\n",
    "   python -m venv venv\n",
    "   ```\n",
    "\n",
    "2. **Activate the Virtual Environment**:\n",
    "\n",
    "   - **Linux & Mac**:\n",
    "     \n",
    "     ```bash\n",
    "     source venv/bin/activate\n",
    "     ```\n",
    "\n",
    "   - **Windows (PowerShell)**:\n",
    "\n",
    "     ```bash\n",
    "     .\\venv\\Scripts\\Activate.ps1\n",
    "     ```\n",
    "\n",
    "3. **Install Required Packages**:\n",
    "\n",
    "   After activating your virtual environment, you can install required packages using pip. If the project provides a `requirements.txt` file (we have `confluent_kafka` and `python-dotenv`), you can install all the required packages with:\n",
    "\n",
    "   ```bash\n",
    "   pip install confluent_kafka python-dotenv\n",
    "   \n",
    "   ```\n",
    "\n",
    "4. **Secrets** \n",
    "\n",
    "   Get the description of the server.\n",
    "   \n",
    "   ```\n",
    "   confluent kafka cluster describe\n",
    "\n",
    "   ```\n",
    "   \n",
    "   ```\n",
    "         > confluent kafka cluster describe\n",
    "      +----------------------+--------------------------------------------------------+\n",
    "      | Current              | true                                                   |\n",
    "      | ID                   | lkc-v1x365                                             |\n",
    "      | Name                 | cluster_0                                              |\n",
    "      | Type                 | BASIC                                                  |\n",
    "      | Ingress Limit (MB/s) | 250                                                    |\n",
    "      | Egress Limit (MB/s)  | 750                                                    |\n",
    "      | Storage              | 5 TB                                                   |\n",
    "      | Provider             | gcp                                                    |\n",
    "      | Region               | us-west4                                               |\n",
    "      | Availability         | single-zone                                            |\n",
    "      | Status               | UP                                                     |\n",
    "      | Endpoint             | SASL_SSL://pkc-lzvrd.us-west4.gcp.confluent.cloud:9092 |\n",
    "      | REST Endpoint        | https://pkc-lzvrd.us-west4.gcp.confluent.cloud:443     |\n",
    "      | Topic Count          | 7                                                      |\n",
    "      +----------------------+--------------------------------------------------------+\n",
    "   ```\n",
    "   \n",
    "   ```\n",
    "   confluent api-key create --resource {id}\n",
    "   ```\n",
    "\n",
    "   ```\n",
    "      > confluent api-key create --resource  lkc-v1x365\n",
    "      It may take a couple of minutes for the API key to be ready.\n",
    "      Save the API key and secret. The secret is not retrievable later.\n",
    "      +------------+------------------------------------------------------------------+\n",
    "      | API Key    | 4REPMBKZ2PYXJ23S                                                 |\n",
    "      | API Secret | bosLhayIKi6G6BAEmh9mhtzAb9kgwB+D2zAuSpfrF962wWt6ZuXpFODjL7NDHFeT |\n",
    "      +------------+------------------------------------------------------------------+```\n",
    "   ```\n",
    "\n",
    "   Create a `.env` file in your project directory with the following content:\n",
    "\n",
    "   ```\n",
    "   BOOTSTRAP_SERVERS={Endpoint}\n",
    "   SECURITY_PROTOCOL=SASL_SSL\n",
    "   SASL_MECHANISMS=PLAIN\n",
    "   SASL_USERNAME={API Key}\n",
    "   SASL_PASSWORD={API Secret}\n",
    "   ```\n",
    "---\n",
    "\n",
    "## (Optional) If you're using Jupyter, specify Python Kernel within Jupyter Notebook (ipynb)\n",
    "\n",
    "If you're using Jupyter Notebook or Jupyter Lab, it's important to ensure that the notebook is using the correct Python kernel, especially if you have multiple Python environments or versions.\n",
    "\n",
    "1. **Install `ipykernel`**:\n",
    "   \n",
    "   After activating your virtual environment, ensure you have `ipykernel` installed:\n",
    "\n",
    "   ```bash\n",
    "   pip install ipykernel\n",
    "   ```\n",
    "\n",
    "2. **Choose the Correct Kernel in Jupyter**:\n",
    "\n",
    "   - Start Jupyter Notebook or Jupyter Lab.\n",
    "   - Open your `.ipynb` notebook.\n",
    "   - From the menu, go to `Kernel` -> `Change kernel` and select `venv` (or the name you provided in the previous step).\n",
    "   \n",
    "Now, your Jupyter notebook will use the Python version from your virtual environment and any packages you've installed in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic topic_example_v1 already exists\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "## Not recommended. Secrets are open to public.\n",
    "# def load_config():\n",
    "#     \"\"\"Load Kafka configuration.\"\"\"\n",
    "#     return {\n",
    "#         'bootstrap.servers': '{server}',\n",
    "#         'security.protocol': '{}',\n",
    "#         'sasl.mechanisms': '{}',\n",
    "#         'sasl.username': '{api key}',\n",
    "#         'sasl.password': '{api password}'\n",
    "#     }\n",
    "    \n",
    "## Recommended way of loading secrets from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "def load_config():\n",
    "    \"\"\"Load Kafka configuration.\"\"\"\n",
    "    return {\n",
    "        'bootstrap.servers': os.getenv('BOOTSTRAP_SERVERS'),\n",
    "        'security.protocol': os.getenv('SECURITY_PROTOCOL'),\n",
    "        'sasl.mechanisms': os.getenv('SASL_MECHANISMS'),\n",
    "        'sasl.username': os.getenv('SASL_USERNAME'),\n",
    "        'sasl.password': os.getenv('SASL_PASSWORD')\n",
    "    }\n",
    "\n",
    "## \n",
    "def topic_exists(admin_client, topic_name):\n",
    "    \"\"\"Check topic existence.\"\"\"\n",
    "    return topic_name in set(admin_client.list_topics(timeout=5).topics.keys())\n",
    "\n",
    "def create_topic(admin_client, topic_name, partitions=1, replication_factor=1, config={}):\n",
    "    \"\"\"Create topic if not existing.\"\"\"\n",
    "    if not topic_exists(admin_client, topic_name):\n",
    "        new_topic = [\n",
    "            NewTopic(\n",
    "                topic_name, \n",
    "                num_partitions=partitions, \n",
    "                replication_factor=replication_factor, \n",
    "                config=config)]\n",
    "        created_topic = admin_client.create_topics(new_topic)\n",
    "        for topic, f in created_topic.items():\n",
    "            try:\n",
    "                f.result()\n",
    "                print(f\"Topic {topic} created\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to create topic {topic}: {e}\")\n",
    "    else:\n",
    "        print(f\"Topic {topic_name} already exists\")\n",
    "\n",
    "# Main execution\n",
    "conf = load_config()\n",
    "admin_client = AdminClient(conf)\n",
    "topic_name = \"topic_example_v1\"\n",
    "\n",
    "# Example topic config\n",
    "topic_config = {'cleanup.policy': 'compact'} \n",
    "# setting 'cleanup.policy': 'compact' ensures that the topic retains only the latest message for a particular key, discarding older messages for the same key.\n",
    "\n",
    "create_topic(admin_client, topic_name, partitions=3, replication_factor=3, config=topic_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_3_producer_trial3_applicants',\n",
       " 'test_1_topic',\n",
       " 'demo_3_producer_trial2_soccer',\n",
       " 'demo_3_producer_trial3_evaluation',\n",
       " 'demo_3_producer_trial1',\n",
       " 'demo1_free_text',\n",
       " 'topic_example_v1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all topics \n",
    "# https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html\n",
    "\n",
    "topic_metadata = admin_client.list_topics(timeout=5)\n",
    "list(topic_metadata.topics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
