{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Asynchronous Producer w/ Serialization\n",
    "\n",
    "Serialization with JSON:\n",
    "\n",
    "- The serialization in `RiderRequest` now produces a formatted string as per your new requirements.\n",
    "- In the `produce_messages()` function, I've created an instance of `RiderRequest` and then called the `serialize()` method on it to generate the desired message value.\n",
    "- You had commas at the end of your lat and long assignments, which would make them tuples. I've corrected that mistake.\n",
    "\n",
    "\n",
    "The `dataclass` decorator plays a couple roles in this producer code that uses serialization. It provides a structured *data model* that serializes cleanly. The serialization happens outside of the class, so dataclasses are not required. But they make the code and data model clearer.\n",
    "\n",
    "1. It defines the RiderRequest data model in a structured way:\n",
    "\n",
    "- The fields (name, lat, long) are explicitly declared with types.\n",
    "\n",
    "- Using a class lets you encapsulate serialization logic in the serialize() method. \n",
    "\n",
    "- The dataclass decorator autogenerates __init__, __repr__, etc.\n",
    "\n",
    "2. It allows creating RiderRequest objects easily:\n",
    "\n",
    "- Can instantiate with RiderRequest(name, lat, long) \n",
    "\n",
    "- Cleaner than using a dictionary or tuple\n",
    "\n",
    "3. It integrates well with serialization:\n",
    "\n",
    "- Libraries like Avro/Protobuf work well with classes/structs\n",
    "\n",
    "- The data is organized logically for serialization\n",
    "\n",
    "- serialize() method has access to fields directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic topic_example_v1 has been created\n",
    "\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "# def load_config():\n",
    "#     \"\"\"Load Kafka configuration.\"\"\"\n",
    "#     return {\n",
    "#         'bootstrap.servers': '{server}',\n",
    "#         'security.protocol': '{}',\n",
    "#         'sasl.mechanisms': '{}',\n",
    "#         'sasl.username': '{api key}',\n",
    "#         'sasl.password': '{api password}'\n",
    "#     }\n",
    "    \n",
    "## Recommended way of loading secrets from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "def load_config():\n",
    "    \"\"\"Load Kafka configuration.\"\"\"\n",
    "    return {\n",
    "        'bootstrap.servers': os.getenv('BOOTSTRAP_SERVERS'),\n",
    "        'security.protocol': os.getenv('SECURITY_PROTOCOL'),\n",
    "        'sasl.mechanisms': os.getenv('SASL_MECHANISMS'),\n",
    "        'sasl.username': os.getenv('SASL_USERNAME'),\n",
    "        'sasl.password': os.getenv('SASL_PASSWORD')\n",
    "    }\n",
    "\n",
    "# in python \n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_3_producer_trial3_applicants',\n",
       " 'test_1_topic',\n",
       " 'demo_3_producer_trial2_soccer',\n",
       " 'demo_3_producer_trial3_evaluation',\n",
       " 'demo_3_producer_trial1',\n",
       " 'demo1_free_text',\n",
       " 'topic_example_v1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "admin_client = AdminClient(config)\n",
    "\n",
    "# List all topics \n",
    "# https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html\n",
    "\n",
    "topic_metadata = admin_client.list_topics(timeout=5)\n",
    "list(topic_metadata.topics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function\n",
    "\n",
    "# Producer callback\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback to report the result of the produce operation.\"\"\"\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "@dataclass\n",
    "class RiderRequest:\n",
    "    name: str\n",
    "    lat: float\n",
    "    long: float\n",
    "\n",
    "    def serialize(self) -> str:\n",
    "        \"\"\"Serializes the object in the desired string format\"\"\"\n",
    "        return f\"rider {self.name} requests a car at ({self.lat:.2f}, {self.long:.2f})\"\n",
    "\n",
    "def produce_messages(producer, topic_name, num_messages=10):\n",
    "    names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "\n",
    "    for i in range(num_messages):\n",
    "        name = random.choice(names)\n",
    "        lat = random.uniform(-90, 90)\n",
    "        long = random.uniform(-180, 180)\n",
    "        message_key = f\"rider-{name}-{i}\"  # Just as an example. Choose a meaningful key if needed.\n",
    "\n",
    "        ## serialization of the message_value\n",
    "        request = RiderRequest(name=name, lat=lat, long=long)\n",
    "        serialized_message = request.serialize()\n",
    "\n",
    "        print(serialized_message)\n",
    "        producer.produce(topic_name, key=message_key, value=serialized_message, callback=delivery_report)\n",
    "        producer.poll(0.1)\n",
    "    producer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define message to generate\n",
    "\n",
    "# import random\n",
    "# def produce_messages(producer, topic_name, num_messages=10):\n",
    "#     \"\"\"Produce messages with the given format.\"\"\"\n",
    "#     names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "\n",
    "#     for i in range(num_messages):\n",
    "#         name = random.choice(names)\n",
    "#         lat = random.uniform(-90, 90)\n",
    "#         long = random.uniform(-180, 180)\n",
    "#         message_key = f\"rider-{name}-{i}\"  # Just as an example. Choose a meaningful key if needed.\n",
    "#         message_value = f\"rider {name} requests a car at ({lat:.2f}, {long:.2f})\"\n",
    "        \n",
    "#         producer.produce(topic_name, key=message_key, value=message_value, callback=delivery_report)\n",
    "#         producer.poll(0.1)  # To trigger the delivery report callback for feedback\n",
    "\n",
    "#     producer.flush()  # Ensure all messages are sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rider Bob requests a car at (-27.66, 130.09)\n",
      "rider Charlie requests a car at (65.48, -90.80)\n",
      "rider Alice requests a car at (72.15, -110.09)\n",
      "rider Alice requests a car at (32.27, -95.44)\n",
      "rider Alice requests a car at (-39.97, -168.07)\n",
      "rider Alice requests a car at (-33.27, -85.01)\n",
      "rider Charlie requests a car at (-19.57, 100.28)\n",
      "rider Bob requests a car at (-11.50, 141.31)\n",
      "Message delivered to topic_example_v1 [2] at offset 541\n",
      "Message delivered to topic_example_v1 [2] at offset 542\n",
      "rider Alice requests a car at (38.43, 40.31)\n",
      "Message delivered to topic_example_v1 [0] at offset 520\n",
      "Message delivered to topic_example_v1 [0] at offset 521\n",
      "Message delivered to topic_example_v1 [0] at offset 522\n",
      "rider Bob requests a car at (0.37, 30.56)\n",
      "Message delivered to topic_example_v1 [2] at offset 543\n",
      "Message delivered to topic_example_v1 [1] at offset 569\n",
      "Message delivered to topic_example_v1 [1] at offset 570\n",
      "Message delivered to topic_example_v1 [1] at offset 571\n",
      "Message delivered to topic_example_v1 [1] at offset 572\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "## main: Producer\n",
    "producer = Producer(config)\n",
    "topic_name = \"topic_example_v1\"\n",
    "produce_messages(producer, topic_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
