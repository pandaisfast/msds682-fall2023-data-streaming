{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - Compare Async and Sync Producers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic topic_example_v1 has been created\n",
    "\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "# def load_config():\n",
    "#     \"\"\"Load Kafka configuration.\"\"\"\n",
    "#     return {\n",
    "#         'bootstrap.servers': '{server}',\n",
    "#         'security.protocol': '{}',\n",
    "#         'sasl.mechanisms': '{}',\n",
    "#         'sasl.username': '{api key}',\n",
    "#         'sasl.password': '{api password}'\n",
    "#     }\n",
    "    \n",
    "## Recommended way of loading secrets from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "def load_config():\n",
    "    \"\"\"Load Kafka configuration.\"\"\"\n",
    "    return {\n",
    "        'bootstrap.servers': os.getenv('BOOTSTRAP_SERVERS'),\n",
    "        'security.protocol': os.getenv('SECURITY_PROTOCOL'),\n",
    "        'sasl.mechanisms': os.getenv('SASL_MECHANISMS'),\n",
    "        'sasl.username': os.getenv('SASL_USERNAME'),\n",
    "        'sasl.password': os.getenv('SASL_PASSWORD')\n",
    "    }\n",
    "\n",
    "# in python \n",
    "config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_3_producer_trial3_applicants',\n",
       " 'test_1_topic',\n",
       " 'demo_3_producer_trial2_soccer',\n",
       " 'demo_3_producer_trial3_evaluation',\n",
       " 'demo_3_producer_trial1',\n",
       " 'demo1_free_text',\n",
       " 'topic_example_v1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "admin_client = AdminClient(config)\n",
    "\n",
    "# List all topics \n",
    "# https://docs.confluent.io/platform/current/clients/confluent-kafka-python/html/index.html\n",
    "\n",
    "topic_metadata = admin_client.list_topics(timeout=5)\n",
    "list(topic_metadata.topics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callback function\n",
    "\n",
    "# Producer callback\n",
    "def delivery_report(err, msg):\n",
    "    \"\"\"Callback to report the result of the produce operation.\"\"\"\n",
    "    if err is not None:\n",
    "        print(f\"Message delivery failed: {err}\")\n",
    "    else:\n",
    "        print(f\"Message delivered to {msg.topic()} [{msg.partition()}] at offset {msg.offset()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to topic_example_v1 [2] at offset 526\n",
      "Message delivered to topic_example_v1 [2] at offset 527\n",
      "Message delivered to topic_example_v1 [0] at offset 507\n",
      "Message delivered to topic_example_v1 [0] at offset 508\n",
      "Message delivered to topic_example_v1 [0] at offset 509\n",
      "Message delivered to topic_example_v1 [1] at offset 547\n",
      "Message delivered to topic_example_v1 [1] at offset 548\n",
      "Message delivered to topic_example_v1 [1] at offset 549\n",
      "Message delivered to topic_example_v1 [1] at offset 550\n",
      "Message delivered to topic_example_v1 [1] at offset 551\n"
     ]
    }
   ],
   "source": [
    "# Define message to generate\n",
    "\n",
    "import random\n",
    "def produce_messages(producer, topic_name, num_messages=10):\n",
    "    \"\"\"Produce messages with the given format.\"\"\"\n",
    "    names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "\n",
    "    for i in range(num_messages):\n",
    "        name = random.choice(names)\n",
    "        lat = random.uniform(-90, 90)\n",
    "        long = random.uniform(-180, 180)\n",
    "        message_key = f\"rider-{name}-{i}\"  # Just as an example. Choose a meaningful key if needed.\n",
    "        message_value = f\"rider {name} requests a car at ({lat:.2f}, {long:.2f})\"\n",
    "        \n",
    "        producer.produce(topic_name, key=message_key, value=message_value, callback=delivery_report)\n",
    "        producer.poll(0.1)  # To trigger the delivery report callback for feedback\n",
    "\n",
    "    producer.flush()  # Ensure all messages are sent\n",
    "    ## Using producer.flush() before shutting down your producer ensures that all messages are delivered and that any callbacks associated with these messages are executed.\n",
    "\n",
    "from confluent_kafka import Producer\n",
    "\n",
    "## main: Producer\n",
    "producer = Producer(config)\n",
    "topic_name = \"topic_example_v1\"\n",
    "produce_messages(producer, topic_name,num_messages=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## synchronous producer\n",
    "\n",
    "import random\n",
    "def produce_messages_synchronously(producer, topic_name, num_messages=10):\n",
    "    \"\"\"Produce messages synchronously.\"\"\"\n",
    "    names = [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "\n",
    "    for i in range(num_messages):\n",
    "        name = random.choice(names)\n",
    "        lat = random.uniform(-90, 90)\n",
    "        long = random.uniform(-180, 180)\n",
    "        message_key = f\"rider-{name}-{i}\"  # Example key\n",
    "        message_value = f\"rider {name} requests a car at ({lat:.2f}, {long:.2f})\"\n",
    "        \n",
    "        producer.produce(topic_name, key=message_key, value=message_value)\n",
    "        \n",
    "        # Wait for message delivery and handle the result\n",
    "        result = producer.flush(timeout=10)  # Adjust the timeout as needed\n",
    "        \n",
    "        if result > 0:\n",
    "            print(f\"Failed to deliver {result} messages\")\n",
    "        else:\n",
    "            print(\"All messages delivered successfully\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The `producer.flush(timeout=10)` method in the Confluent Kafka Python client is used to ensure that all outstanding/queued messages are delivered and all callbacks are invoked. The `flush()` method works by waiting until all the messages in the producer's local queue are delivered to the Kafka broker, or the provided timeout (in seconds) expires.\n",
    "\n",
    "Here's a breakdown of what happens:\n",
    "\n",
    "1. The `flush()` method initiates the delivery of all the messages that are currently in the producer's local queue.\n",
    "\n",
    "2. It then waits for the acknowledgments from the broker for these messages.\n",
    "\n",
    "3. If the acknowledgments for all the messages are received before the provided timeout, `flush()` will return 0, indicating that all messages have been successfully delivered.\n",
    "\n",
    "4. If the provided timeout expires before acknowledgments for all messages are received, `flush()` will return a non-zero value indicating the number of messages that remain in the queue (i.e., the number of messages that haven't been successfully delivered). \n",
    "\n",
    "In the synchronous producer code you provided, after each message is produced, the `flush()` method is called with a timeout of 10 seconds. This means that after producing each message, the code will wait up to 10 seconds for the acknowledgment of that message from the Kafka broker. If the acknowledgment is received within that timeframe, the message is considered delivered; otherwise, the code will move to the next iteration of the loop (or exit the loop) and the `if-else` block will print out how many messages failed to be delivered.\n",
    "\n",
    "This use of `flush()` after producing each message gives the producer synchronous behavior: it won't proceed until it has confirmation that the current message has been delivered or the timeout is reached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n",
      "All messages delivered successfully\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "# Main Execution\n",
    "producer = Producer(config)\n",
    "topic_name = \"topic_example_v1\"\n",
    "produce_messages_synchronously(producer, topic_name, num_messages=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
