# Lec 2: Additional Topics

Author: Jeremy Gu

!!! note

    In each lecture, we will have a section called "Additional Topics" covering concepts that, due to our fast-paced curriculum, we may not have time to cover in class. However, I believe understanding these is important for fully mastering data streaming. I may also include recommended readings and coding exercises to reinforce your learning. Note that additional topics will not be on the midterm exam. In your future work, I encourage revisiting these to strengthen your data streaming knowledge. 

## Asynchronous Producer and Synchronous Producer

Below is a table that summarizes the use of `flush()`, `poll()`, and other methods for both asynchronous and synchronous Kafka producers:

| **Method/Action** | **Asynchronous Producer** | **Synchronous Producer** |
|--------------------|---------------------------|--------------------------|
| **flush()**       | **Used (After all messages)** - Called once after the loop has produced all messages to ensure that all of them have been delivered. It waits up to the given timeout for the delivery report callbacks to be triggered. | **Used (After each message)** - Called within the loop, after each `produce()`, to ensure that the current message is delivered and acknowledged before sending the next one. |
| **poll()**        | **Used** - Can be used within the loop or after it, primarily to trigger the delivery report callback and get feedback about the delivery status of messages. If used after the loop (as in the provided example), it will process delivery reports for all previously sent messages.| *Optional* - Not typically required in a purely synchronous producer since `flush()` waits for message acknowledgment. However, if you wanted feedback about delivery status after each message, you could use it. |
| **callback**      | **Used** - Callback functions (like `delivery_report`) are used to handle delivery reports asynchronously. They provide feedback about the delivery status of each message. | *Optional* - While callbacks can be used in synchronous producers, they're not as essential since you're relying on `flush()` to wait for acknowledgment. However, callbacks can provide more detailed information about the delivery. |

Remember that in real-world scenarios, you might find hybrid approaches based on the exact requirements of your application. The above distinctions are generalized to help you understand the conceptual differences between the two types of producers.

## Terminology Review

| Term | Definition | Example |
|-|-|-|
| Synchronous | Operations prevent subsequent operations from starting until they are completed. | When on a phone call, you can't start a second call. |
| Sequential | Operations occur in a specific order, one after the other. | For breakfast, first brew the coffee, then fry the eggs. |
| Parallel | Multiple operations or tasks execute independently at the exact same time. | A multi-core CPU can execute multiple tasks simultaneously. |
| Concurrent | Multiple operations or tasks start within the same timeframe, but might not start at the exact same moment; they may interleave or execute simultaneously. | While cooking, you can concurrently do laundry. |
| Asynchronous | Once an operation starts, there's no need to wait for its completion; you can continue other operations. Upon completion of the original operation, a notification is typically given, often through mechanisms like callbacks. | Email is sent in the background; you're notified once it's sent. |


## Fire and Forget

"Fire and Forget" is a term commonly used in distributed systems and messaging architectures to describe a pattern where the producer sends a message and doesn't wait or care about the acknowledgment of its receipt or its processing status. In the context of Kafka, this would mean sending a message to the broker without waiting for any acknowledgment of its delivery.

In the Kafka producer scenarios we discussed:

1. **Asynchronous Producer:** This can be considered a form of "Fire and Forget" if you remove the callbacks and the `flush()` method. You just "fire" messages to the broker in a loop and don't bother checking if they were received or if there were any errors.

2. **Synchronous Producer:** This is the opposite of "Fire and Forget." Every message is sent, and the producer waits for its acknowledgment before proceeding.

For a true "Fire and Forget" scenario with a Kafka producer in Python, the code might look something like:

```python
from confluent_kafka import Producer

config = {
    # ... your Kafka configuration ...
}

producer = Producer(config)

def produce_messages_fire_and_forget(producer, topic_name, num_messages=10):
    """Fire and forget message production."""
    for _ in range(num_messages):
        message_value = "Some message value"
        producer.produce(topic_name, value=message_value)
        
# Use the function
produce_messages_fire_and_forget(producer, "your_topic_name")
```

In the above, messages are sent without any checks or waits for acknowledgment. This method can achieve **higher throughput** because it doesn't involve the overhead of checking message delivery status. However, it comes at the **potential cost of not knowing** about failed deliveries, so it's best used in scenarios where occasional message loss is acceptable.

## Producer Congiuration

| Configuration         | Default Value  | Recommended Value | Description                                                                                              |
|-----------------------|---------------|---------------------|-------------------------------------------------------------------------------------------------------|
| `client.id`               | (none)           | (unique value)        | Identifier for the client in the Kafka cluster. Useful for tracking and debugging.                           |
| `retries`                   | 2147483647   | (depends on use case) | The number of retry attempts. A high default ensures durability but can be adjusted based on use case.       |
| `enable.idempotence` | false           | true                     | Ensures that messages are delivered exactly once by allowing retries without duplication.                       |
| `acks`                      | all or -1                 | all or -1            | The number of acknowledgments the producer requires the broker to receive before considering a message sent.    |
| `compression.type`     | none           | (depends on use case) | Type of compression to use (`none`, `gzip`, `snappy`, `lz4`, `zstd`). Chosen based on data and performance needs. |

[Source of Truth](https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md) is from the confluent github repo: https://github.com/confluentinc/librdkafka/blob/master/CONFIGURATION.md.


Based on [Apache Kafka Message Compression](https://www.confluent.io/blog/apache-kafka-message-compression/) published on 9/18/2023, here are the relevant passages that pertain to the topic-level compression and its precedence:

1. **Topic-Level Compression Precedence**:
   > "Typically, it works in the following manner when the producer is responsible for compression, and the topic’s compression.type is producer."
   
2. **Mismatch in Compression Settings**:
   > "Brokers always perform some amount of batch decompression in order to validate data."
   > "The following scenarios always require full payload decompression:
     The producer compresses batches (i.e., compression.type isn’t none), and the topic-level compression.type specifies a different codec or is uncompressed."
     

### Choice of Compression Types

When decompression speed is critical, the following compression algorithms are commonly recommended in Kafka and other systems:

1. **Snappy**: Developed by Google, Snappy prioritizes speed over compression ratio. It doesn't compress as tightly as some other algorithms, but it decompresses very quickly.

2. **LZ4**: This is another compression algorithm that's designed for fast decompression speeds. In many benchmarks, LZ4 has been shown to be faster than Snappy, both in terms of compression and decompression, but with a slightly better compression ratio than Snappy.

Between the two, LZ4 is often **recommended** in Kafka for performance reasons, but the best choice can vary depending on the specific nature of the data and the requirements of the use case. Always consider benchmarking with your actual data to determine which one meets your needs best.

When network overhead is critical, meaning you want to minimize the amount of data sent over the network, you should opt for compression algorithms that provide the highest compression ratios, even if they are slower in terms of compression and decompression speed. Here are the common choices:

1. **gzip**: This is a widely-used compression algorithm that typically provides a good balance between compression ratio and speed. While it's not the fastest in terms of compression or decompression, it usually achieves smaller compressed sizes compared to faster algorithms like Snappy or LZ4.

2. **zstd (Zstandard)**: Developed by Facebook, zstd offers compression ratios comparable to gzip but at much faster speeds, especially in its higher compression levels. This makes zstd a great choice for scenarios where both network bandwidth and speed are concerns.

For maximum reduction in network overhead, you might lean toward gzip or zstd. zstd is often **recommended** over gzip due to its better speed while maintaining a similar, if not better, compression ratio. As always, it's beneficial to benchmark different algorithms with your actual data to determine the best fit for your specific needs.

### client.id

The `client.id` is a configuration setting for Kafka clients (both producers and consumers). It's an identifier for the client in the Kafka cluster. This ID is used in logs, metrics, and for debugging purposes to identify the source of requests to the broker.

Having a unique `client.id` for each client allows administrators and developers to track requests, observe behavior, and troubleshoot issues more effectively because they can see which client is making which requests.

**Simple Example**:
Let's say you have a system with multiple Kafka producers, one that sends user activity data and another that sends system metrics. You can assign unique client IDs to each of them:

- For the producer that sends user activity data: `client.id=user-activity-producer`
- For the producer that sends system metrics: `client.id=system-metrics-producer`

Now, when you look at the logs or metrics from the Kafka broker, you can quickly identify which client (producer) is the source of a particular request or potential issue just by checking the `client.id`. This is especially helpful in environments with many clients interacting with a Kafka cluster.

### Idempotence

When retries are enabled, enabling idempotence ensures messages remain in their intended order. For example, if messages A, B, and C are sent, but B fails initially while C succeeds, retries without idempotence might lead to an A, C, B order. With idempotence, the order A, B, C is preserved.